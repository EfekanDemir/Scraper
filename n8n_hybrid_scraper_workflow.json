{
  "name": "Hybrid Web Scraper - 3 Technique Integration",
  "nodes": [
    {
      "parameters": {
        "url": "={{ $json.target_url || 'https://www.local-rank.report/scan/e029a8c3-3891-4dce-a61d-1406929d232a' }}",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "User-Agent",
              "value": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            },
            {
              "name": "Accept",
              "value": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"
            },
            {
              "name": "Accept-Language",
              "value": "en-US,en;q=0.9"
            },
            {
              "name": "Cache-Control",
              "value": "no-cache"
            }
          ]
        },
        "options": {
          "timeout": 30000,
          "followRedirect": true,
          "response": {
            "responseFormat": "string"
          }
        }
      },
      "id": "initial-html-request",
      "name": "üåê Initial HTML Request",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [400, 200],
      "notes": "Technique 1: HTML Parsing - ƒ∞lk adƒ±m: Ham HTML i√ßeriƒüini al"
    },
    {
      "parameters": {
        "functionCode": "// üîç TECHNIQUE 1: HTML PARSING - BeautifulSoup Equivalent\n// HTML i√ßeriƒüinden statik verileri √ßƒ±kar\n\nconst htmlContent = items[0].json.data;\n\n// Helper function: Extract text safely\nfunction extractText(htmlContent, selector, defaultValue = 'N/A') {\n  try {\n    const regex = new RegExp(`<[^>]*class=\"[^\"]*${selector}[^\"]*\"[^>]*>([^<]*)</`, 'i');\n    const match = htmlContent.match(regex);\n    return match ? match[1].trim() : defaultValue;\n  } catch (e) {\n    return defaultValue;\n  }\n}\n\n// Helper function: Extract table data\nfunction extractTableData(htmlContent, tableClass) {\n  const results = [];\n  try {\n    const tableRegex = new RegExp(`<table[^>]*class=\"[^\"]*${tableClass}[^>]*>([\\s\\S]*?)</table>`, 'i');\n    const tableMatch = htmlContent.match(tableRegex);\n    \n    if (tableMatch) {\n      const tableContent = tableMatch[1];\n      const rowRegex = /<tr[^>]*>([\\s\\S]*?)</tr>/gi;\n      let rowMatch;\n      \n      while ((rowMatch = rowRegex.exec(tableContent)) !== null) {\n        const rowContent = rowMatch[1];\n        const cellRegex = /<t[dh][^>]*>([\\s\\S]*?)</t[dh]>/gi;\n        const cells = [];\n        let cellMatch;\n        \n        while ((cellMatch = cellRegex.exec(rowContent)) !== null) {\n          cells.push(cellMatch[1].replace(/<[^>]*>/g, '').trim());\n        }\n        \n        if (cells.length > 0) {\n          results.push(cells);\n        }\n      }\n    }\n  } catch (e) {\n    console.log('Table extraction error:', e);\n  }\n  \n  return results;\n}\n\n// 1. Scan Information (√ñzet Bilgiler)\nconst scanInfo = {};\ntry {\n  const scanTable = extractTableData(htmlContent, 'scan-info');\n  scanTable.forEach(row => {\n    if (row.length >= 2) {\n      scanInfo[row[0]] = row[1];\n    }\n  });\n} catch (e) {\n  console.log('Scan info extraction error:', e);\n}\n\n// 2. Rank Summary \nconst rankSummary = {};\ntry {\n  const rankTable = extractTableData(htmlContent, 'rank-summary');\n  rankTable.forEach(row => {\n    if (row.length >= 2) {\n      rankSummary[row[0]] = row[1];\n    }\n  });\n} catch (e) {\n  console.log('Rank summary extraction error:', e);\n}\n\n// 3. Competitors List\nconst competitors = [];\ntry {\n  const competitorTable = extractTableData(htmlContent, 'competitors');\n  if (competitorTable.length > 1) { // Skip header row\n    for (let i = 1; i < competitorTable.length; i++) {\n      const row = competitorTable[i];\n      if (row.length >= 8) {\n        competitors.push({\n          name: row[0] || 'N/A',\n          rating: row[1] || 'N/A',\n          address: row[2] || 'N/A',\n          categories: row[3] || 'N/A',\n          website: row[4] || 'N/A',\n          photos: row[5] || 'N/A',\n          claimed: row[6] || 'N/A',\n          locations: row[7] || 'N/A',\n          avgRank: row[8] || 'N/A'\n        });\n      }\n    }\n  }\n} catch (e) {\n  console.log('Competitors extraction error:', e);\n}\n\n// 4. Sponsored Listings\nconst sponsoredListings = [];\ntry {\n  const sponsoredTable = extractTableData(htmlContent, 'sponsored');\n  if (sponsoredTable.length > 1) { // Skip header row\n    for (let i = 1; i < sponsoredTable.length; i++) {\n      const row = sponsoredTable[i];\n      if (row.length >= 4) {\n        sponsoredListings.push({\n          name: row[0] || 'N/A',\n          type: row[1] || 'N/A',\n          url: row[2] || 'N/A',\n          locations: row[3] || 'N/A'\n        });\n      }\n    }\n  }\n} catch (e) {\n  console.log('Sponsored listings extraction error:', e);\n}\n\n// Return extracted HTML data\nreturn [{\n  json: {\n    technique: 'HTML_PARSING',\n    method: 'BeautifulSoup_Equivalent',\n    htmlData: {\n      scanInfo: scanInfo,\n      rankSummary: rankSummary,\n      competitors: competitors,\n      sponsoredListings: sponsoredListings\n    },\n    rawHtml: htmlContent,\n    extractedAt: new Date().toISOString()\n  }\n}];"
      },
      "id": "html-parser-function",
      "name": "üîç HTML Parser (Technique 1)",
      "type": "n8n-nodes-base.function",
      "typeVersion": 2,
      "position": [600, 100],
      "notes": "HTML Parsing: BeautifulSoup equivalent - Statik HTML verilerini √ßƒ±kar"
    },
    {
      "parameters": {
        "functionCode": "// üöÄ TECHNIQUE 2: JAVASCRIPT EXTRACTION - Regex Parsing\n// JavaScript kodundan dinamik verileri √ßƒ±kar\n\nconst htmlContent = items[0].json.data;\n\n// Helper function: Safe JSON parse\nfunction safeJsonParse(str) {\n  try {\n    return JSON.parse(str);\n  } catch (e) {\n    return null;\n  }\n}\n\n// 1. Extract pinz array (49 lokasyon verisi)\nlet pinzData = [];\ntry {\n  const pinzRegex = /var\\s+pinz\\s*=\\s*(\\[[\\s\\S]*?\\]);/i;\n  const pinzMatch = htmlContent.match(pinzRegex);\n  \n  if (pinzMatch) {\n    const pinzJson = safeJsonParse(pinzMatch[1]);\n    if (pinzJson && Array.isArray(pinzJson)) {\n      pinzData = pinzJson.map((item, index) => ({\n        id: index + 1,\n        lat: item.lat || 0,\n        lng: item.lng || 0,\n        title: item.title || 'N/A',\n        url: item.url || '',\n        search_guid: item.search_guid || '',\n        place_id: item.place_id || ''\n      }));\n    }\n  }\n} catch (e) {\n  console.log('Pinz extraction error:', e);\n}\n\n// 2. Extract scan_guid\nlet scanGuid = '';\ntry {\n  const scanGuidRegex = /scan_guid['\\\"]?\\s*[:=]\\s*['\\\"]([^'\\\"]+)['\\\"]/i;\n  const scanMatch = htmlContent.match(scanGuidRegex);\n  \n  if (scanMatch) {\n    scanGuid = scanMatch[1];\n  }\n} catch (e) {\n  console.log('Scan GUID extraction error:', e);\n}\n\n// 3. Extract place_id\nlet placeId = '';\ntry {\n  const placeIdRegex = /place_id['\\\"]?\\s*[:=]\\s*['\\\"]([^'\\\"]+)['\\\"]/i;\n  const placeMatch = htmlContent.match(placeIdRegex);\n  \n  if (placeMatch) {\n    placeId = placeMatch[1];\n  }\n} catch (e) {\n  console.log('Place ID extraction error:', e);\n}\n\n// 4. Extract additional JavaScript variables\nlet additionalJsData = {};\ntry {\n  // Search for other relevant JS variables\n  const jsVarPatterns = [\n    { name: 'business_name', pattern: /business_name['\\\"]?\\s*[:=]\\s*['\\\"]([^'\\\"]+)['\\\"]/i },\n    { name: 'search_term', pattern: /search_term['\\\"]?\\s*[:=]\\s*['\\\"]([^'\\\"]+)['\\\"]/i },\n    { name: 'location', pattern: /location['\\\"]?\\s*[:=]\\s*['\\\"]([^'\\\"]+)['\\\"]/i },\n    { name: 'language', pattern: /language['\\\"]?\\s*[:=]\\s*['\\\"]([^'\\\"]+)['\\\"]/i }\n  ];\n  \n  jsVarPatterns.forEach(pattern => {\n    const match = htmlContent.match(pattern.pattern);\n    if (match) {\n      additionalJsData[pattern.name] = match[1];\n    }\n  });\n} catch (e) {\n  console.log('Additional JS data extraction error:', e);\n}\n\n// 5. Extract API endpoints from JavaScript\nlet apiEndpoints = [];\ntry {\n  // Look for fetch() calls or API URLs\n  const fetchRegex = /fetch\\s*\\(\\s*['\\\"]([^'\\\"]+)['\\\"]/gi;\n  let fetchMatch;\n  \n  while ((fetchMatch = fetchRegex.exec(htmlContent)) !== null) {\n    apiEndpoints.push(fetchMatch[1]);\n  }\n  \n  // Look for hardcoded API paths\n  const apiPathRegex = /[\\'\\\"]\\/(?:analytics|scans|api)\\/[^\\'\\\"]+[\\'\\\"]/gi;\n  let apiMatch;\n  \n  while ((apiMatch = apiPathRegex.exec(htmlContent)) !== null) {\n    const cleanPath = apiMatch[0].replace(/['\\\"]/, '');\n    if (!apiEndpoints.includes(cleanPath)) {\n      apiEndpoints.push(cleanPath);\n    }\n  }\n} catch (e) {\n  console.log('API endpoints extraction error:', e);\n}\n\n// Return extracted JavaScript data\nreturn [{\n  json: {\n    technique: 'JAVASCRIPT_EXTRACTION',\n    method: 'Regex_Parsing',\n    jsData: {\n      pinzData: pinzData,\n      scanGuid: scanGuid,\n      placeId: placeId,\n      additionalVars: additionalJsData,\n      apiEndpoints: apiEndpoints,\n      pinzCount: pinzData.length\n    },\n    extractedAt: new Date().toISOString()\n  }\n}];"
      },
      "id": "js-extractor-function",
      "name": "üöÄ JavaScript Extractor (Technique 2)",
      "type": "n8n-nodes-base.function",
      "typeVersion": 2,
      "position": [600, 300],
      "notes": "JavaScript Extraction: Regex Parsing - Dinamik JS verilerini √ßƒ±kar"
    },
    {
      "parameters": {
        "functionCode": "// üîó TECHNIQUE 3 PREPARATION: API CALLS Setup\n// JavaScript verilerinden API √ßaƒürƒ±larƒ± i√ßin parametreleri hazƒ±rla\n\nconst jsData = items[0].json.jsData;\nconst htmlData = items[1].json.htmlData;\n\n// Base URL extraction\nlet baseUrl = '';\ntry {\n  const currentUrl = items[0].json.rawHtml || '';\n  const urlMatch = currentUrl.match(/https?:\\/\\/[^\\/]+/);\n  if (urlMatch) {\n    baseUrl = urlMatch[0];\n  } else {\n    baseUrl = 'https://www.local-rank.report';\n  }\n} catch (e) {\n  baseUrl = 'https://www.local-rank.report';\n}\n\n// Prepare API call parameters\nconst apiCalls = [];\n\n// 1. Competitors API Call\nif (jsData.scanGuid) {\n  apiCalls.push({\n    type: 'competitors',\n    url: `${baseUrl}/scans/get-competitors-list`,\n    params: {\n      scan_guid: jsData.scanGuid\n    },\n    method: 'GET'\n  });\n}\n\n// 2. Analytics API Calls (pinz array'inden)\nif (jsData.pinzData && jsData.pinzData.length > 0) {\n  jsData.pinzData.forEach((pin, index) => {\n    if (pin.url) {\n      apiCalls.push({\n        type: 'analytics',\n        index: index + 1,\n        url: pin.url.startsWith('http') ? pin.url : `${baseUrl}${pin.url}`,\n        params: {\n          search_guid: pin.search_guid,\n          place_id: pin.place_id || jsData.placeId\n        },\n        method: 'GET',\n        location: {\n          lat: pin.lat,\n          lng: pin.lng,\n          title: pin.title\n        }\n      });\n    }\n  });\n}\n\n// 3. Compare API Call\nif (jsData.scanGuid && jsData.placeId) {\n  apiCalls.push({\n    type: 'compare',\n    url: `${baseUrl}/scans/compare`,\n    params: {\n      scan: jsData.scanGuid,\n      biz1: jsData.placeId,\n      biz2: jsData.placeId,\n      ts: jsData.pinzCount || 49,\n      v: 1\n    },\n    method: 'GET'\n  });\n}\n\n// Return prepared API calls data\nreturn [{\n  json: {\n    technique: 'API_CALLS_PREPARATION',\n    baseUrl: baseUrl,\n    apiCalls: apiCalls,\n    totalCalls: apiCalls.length,\n    jsData: jsData,\n    htmlData: htmlData,\n    preparedAt: new Date().toISOString()\n  }\n}];"
      },
      "id": "api-preparation-function",
      "name": "üîó API Calls Preparation",
      "type": "n8n-nodes-base.function",
      "typeVersion": 2,
      "position": [800, 200],
      "notes": "API √ßaƒürƒ±larƒ± i√ßin parametreleri hazƒ±rla"
    },
    {
      "parameters": {
        "batchSize": 1,
        "options": {}
      },
      "id": "api-calls-splitter",
      "name": "üì° Split API Calls",
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [1000, 200],
      "notes": "API √ßaƒürƒ±larƒ±nƒ± tek tek i≈ülemek i√ßin b√∂l"
    },
    {
      "parameters": {
        "url": "={{ $json.apiCalls[$json.index].url }}",
        "sendQuery": true,
        "queryParameters": {
          "parameters": "={{ Object.entries($json.apiCalls[$json.index].params).map(([key, value]) => ({ name: key, value: value })) }}"
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "User-Agent",
              "value": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            },
            {
              "name": "Accept",
              "value": "application/json, text/plain, */*"
            },
            {
              "name": "Accept-Language",
              "value": "en-US,en;q=0.9"
            },
            {
              "name": "X-Requested-With",
              "value": "XMLHttpRequest"
            }
          ]
        },
        "options": {
          "timeout": 15000,
          "followRedirect": true,
          "ignoreResponseCode": true,
          "response": {
            "responseFormat": "autodetect"
          }
        }
      },
      "id": "api-request-execution",
      "name": "üåê API Request Execution (Technique 3)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [1200, 200],
      "notes": "Technique 3: API Calls - REST API √ßaƒürƒ±larƒ± ger√ßekle≈ütir"
    },
    {
      "parameters": {
        "functionCode": "// üîó TECHNIQUE 3: API CALLS - Response Processing\n// API yanƒ±tlarƒ±nƒ± i≈üle ve normalize et\n\nconst currentItem = items[0].json;\nconst apiCall = currentItem.apiCalls[currentItem.index];\nconst response = currentItem.data;\n\n// Process API response based on type\nlet processedData = {};\n\ntry {\n  switch (apiCall.type) {\n    case 'competitors':\n      // Process competitors API response\n      if (typeof response === 'object' && response !== null) {\n        processedData = {\n          type: 'competitors_api',\n          data: Array.isArray(response) ? response : [response],\n          count: Array.isArray(response) ? response.length : 1\n        };\n      } else if (typeof response === 'string') {\n        // Try to parse HTML response\n        const competitors = [];\n        const competitorRegex = /<tr[^>]*>([\\s\\S]*?)</tr>/gi;\n        let match;\n        \n        while ((match = competitorRegex.exec(response)) !== null) {\n          const rowData = match[1].replace(/<[^>]*>/g, '').trim();\n          if (rowData && !rowData.includes('Name') && !rowData.includes('Rating')) {\n            competitors.push({ rawData: rowData });\n          }\n        }\n        \n        processedData = {\n          type: 'competitors_api',\n          data: competitors,\n          count: competitors.length,\n          rawHtml: response\n        };\n      }\n      break;\n      \n    case 'analytics':\n      // Process analytics API response\n      processedData = {\n        type: 'analytics_api',\n        locationIndex: apiCall.index,\n        location: apiCall.location,\n        data: response,\n        searchGuid: apiCall.params.search_guid,\n        placeId: apiCall.params.place_id\n      };\n      break;\n      \n    case 'compare':\n      // Process compare API response\n      processedData = {\n        type: 'compare_api',\n        data: response,\n        scanGuid: apiCall.params.scan,\n        businessId: apiCall.params.biz1\n      };\n      break;\n      \n    default:\n      processedData = {\n        type: 'unknown_api',\n        data: response\n      };\n  }\n} catch (e) {\n  console.log('API response processing error:', e);\n  processedData = {\n    type: 'error',\n    error: e.message,\n    rawResponse: response\n  };\n}\n\n// Return processed API data\nreturn [{\n  json: {\n    technique: 'API_CALLS',\n    method: 'REST_API_Processing',\n    apiCall: {\n      type: apiCall.type,\n      url: apiCall.url,\n      params: apiCall.params\n    },\n    processedData: processedData,\n    responseTime: new Date().toISOString(),\n    originalResponse: response\n  }\n}];"
      },
      "id": "api-response-processor",
      "name": "üîÑ API Response Processor",
      "type": "n8n-nodes-base.function",
      "typeVersion": 2,
      "position": [1400, 200],
      "notes": "API yanƒ±tlarƒ±nƒ± i≈üle ve normalize et"
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "api-data-aggregator",
      "name": "üìä API Data Aggregator",
      "type": "n8n-nodes-base.aggregate",
      "typeVersion": 1,
      "position": [1600, 200],
      "notes": "T√ºm API yanƒ±tlarƒ±nƒ± topla"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineAll",
        "options": {}
      },
      "id": "final-data-merger",
      "name": "üîÄ Final Data Merger",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 2.1,
      "position": [1800, 200],
      "notes": "HTML, JS ve API verilerini birle≈ütir"
    },
    {
      "parameters": {
        "functionCode": "// üéØ FINAL DATA PROCESSING: 3 Technique Integration\n// HTML Parsing + JavaScript Extraction + API Calls verilerini birle≈ütir\n\nconst allItems = items;\nlet htmlData = {};\nlet jsData = {};\nlet apiDataArray = [];\n\n// Separate data by technique\nallItems.forEach(item => {\n  if (item.json.technique === 'HTML_PARSING') {\n    htmlData = item.json.htmlData;\n  } else if (item.json.technique === 'JAVASCRIPT_EXTRACTION') {\n    jsData = item.json.jsData;\n  } else if (item.json.technique === 'API_CALLS') {\n    apiDataArray.push(item.json);\n  }\n});\n\n// Process API data by type\nconst competitorsApiData = [];\nconst analyticsApiData = [];\nconst compareApiData = [];\n\napiDataArray.forEach(apiItem => {\n  if (apiItem.processedData) {\n    switch (apiItem.processedData.type) {\n      case 'competitors_api':\n        competitorsApiData.push(apiItem.processedData);\n        break;\n      case 'analytics_api':\n        analyticsApiData.push(apiItem.processedData);\n        break;\n      case 'compare_api':\n        compareApiData.push(apiItem.processedData);\n        break;\n    }\n  }\n});\n\n// Create final integrated dataset\nconst finalData = {\n  // Metadata about the scraping process\n  metadata: {\n    scrapedAt: new Date().toISOString(),\n    scraperVersion: '5.0-hybrid',\n    techniques: [\n      'HTML_PARSING (BeautifulSoup)',\n      'JAVASCRIPT_EXTRACTION (Regex)',\n      'API_CALLS (REST)'\n    ],\n    dataTypes: {\n      htmlData: Object.keys(htmlData).length,\n      jsData: Object.keys(jsData).length,\n      apiCalls: apiDataArray.length\n    }\n  },\n  \n  // Technique 1: HTML Parsing Results\n  staticData: {\n    technique: 'HTML_PARSING',\n    method: 'BeautifulSoup_Equivalent',\n    scanInformation: htmlData.scanInfo || {},\n    rankSummary: htmlData.rankSummary || {},\n    competitors: htmlData.competitors || [],\n    sponsoredListings: htmlData.sponsoredListings || []\n  },\n  \n  // Technique 2: JavaScript Extraction Results\n  dynamicData: {\n    technique: 'JAVASCRIPT_EXTRACTION',\n    method: 'Regex_Parsing',\n    locationData: jsData.pinzData || [],\n    scanGuid: jsData.scanGuid || '',\n    placeId: jsData.placeId || '',\n    additionalVars: jsData.additionalVars || {},\n    detectedEndpoints: jsData.apiEndpoints || []\n  },\n  \n  // Technique 3: API Calls Results\n  deepData: {\n    technique: 'API_CALLS',\n    method: 'REST_API',\n    competitorsApi: competitorsApiData,\n    analyticsApi: analyticsApiData,\n    compareApi: compareApiData,\n    totalApiCalls: apiDataArray.length\n  },\n  \n  // Combined Analysis\n  analysis: {\n    totalLocations: jsData.pinzData ? jsData.pinzData.length : 0,\n    totalCompetitors: htmlData.competitors ? htmlData.competitors.length : 0,\n    totalSponsoredListings: htmlData.sponsoredListings ? htmlData.sponsoredListings.length : 0,\n    apiDataPoints: apiDataArray.length,\n    dataCompleteness: {\n      htmlParsing: Object.keys(htmlData).length > 0,\n      javaScriptExtraction: Object.keys(jsData).length > 0,\n      apiCalls: apiDataArray.length > 0\n    }\n  },\n  \n  // Raw data for debugging\n  rawData: {\n    htmlRaw: htmlData,\n    jsRaw: jsData,\n    apiRaw: apiDataArray\n  }\n};\n\n// Return final integrated data\nreturn [{\n  json: finalData\n}];"
      },
      "id": "final-data-processor",
      "name": "üéØ Final Data Processor",
      "type": "n8n-nodes-base.function",
      "typeVersion": 2,
      "position": [2000, 200],
      "notes": "3 tekniƒüi birle≈ütir ve final veri yapƒ±sƒ±nƒ± olu≈ütur"
    },
    {
      "parameters": {
        "operation": "toJson",
        "options": {
          "fileName": "={{ 'hybrid_scraped_data_' + $now.format('YYYYMMDD_HHmmss') + '.json' }}"
        }
      },
      "id": "json-export",
      "name": "üíæ JSON Export",
      "type": "n8n-nodes-base.convertToFile",
      "typeVersion": 1.1,
      "position": [2200, 100],
      "notes": "JSON formatƒ±nda veri dƒ±≈üa aktarma"
    },
    {
      "parameters": {
        "operation": "fromJson",
        "mode": "autoMapInputData",
        "options": {
          "fileName": "={{ 'hybrid_scraped_data_' + $now.format('YYYYMMDD_HHmmss') + '.xlsx' }}",
          "headerRow": true,
          "sheets": {
            "specifySheets": "defineBelow",
            "sheetOptions": [
              {
                "sheetName": "Metadata",
                "jsonPath": "$.metadata"
              },
              {
                "sheetName": "Static_HTML_Data",
                "jsonPath": "$.staticData"
              },
              {
                "sheetName": "Dynamic_JS_Data",
                "jsonPath": "$.dynamicData.locationData"
              },
              {
                "sheetName": "API_Data",
                "jsonPath": "$.deepData"
              },
              {
                "sheetName": "Analysis",
                "jsonPath": "$.analysis"
              }
            ]
          }
        }
      },
      "id": "excel-export",
      "name": "üìä Excel Export",
      "type": "n8n-nodes-base.convertToFile",
      "typeVersion": 1.1,
      "position": [2200, 200],
      "notes": "Excel formatƒ±nda √ßok sayfa rapor"
    },
    {
      "parameters": {
        "operation": "fromJson",
        "mode": "autoMapInputData",
        "options": {
          "fileName": "={{ 'hybrid_scraped_data_' + $now.format('YYYYMMDD_HHmmss') + '.csv' }}",
          "headerRow": true
        }
      },
      "id": "csv-export",
      "name": "üìã CSV Export",
      "type": "n8n-nodes-base.convertToFile",
      "typeVersion": 1.1,
      "position": [2200, 300],
      "notes": "CSV formatƒ±nda veri dƒ±≈üa aktarma"
    },
    {
      "parameters": {},
      "id": "start-node",
      "name": "‚ñ∂Ô∏è Start",
      "type": "n8n-nodes-base.start",
      "typeVersion": 1,
      "position": [200, 200],
      "notes": "Workflow ba≈ülangƒ±cƒ± - URL input ile ba≈ülar"
    },
    {
      "parameters": {
        "options": {}
      },
      "id": "rate-limiter",
      "name": "‚è≥ Rate Limiter",
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [1100, 300],
      "notes": "API √ßaƒürƒ±larƒ± arasƒ±nda bekleme s√ºresi"
    }
  ],
  "connections": {
    "start-node": {
      "main": [
        [
          {
            "node": "initial-html-request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "initial-html-request": {
      "main": [
        [
          {
            "node": "html-parser-function",
            "type": "main",
            "index": 0
          },
          {
            "node": "js-extractor-function",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "html-parser-function": {
      "main": [
        [
          {
            "node": "api-preparation-function",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "js-extractor-function": {
      "main": [
        [
          {
            "node": "api-preparation-function",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "api-preparation-function": {
      "main": [
        [
          {
            "node": "api-calls-splitter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "api-calls-splitter": {
      "main": [
        [
          {
            "node": "rate-limiter",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "rate-limiter": {
      "main": [
        [
          {
            "node": "api-request-execution",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "api-request-execution": {
      "main": [
        [
          {
            "node": "api-response-processor",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "api-response-processor": {
      "main": [
        [
          {
            "node": "api-data-aggregator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "api-data-aggregator": {
      "main": [
        [
          {
            "node": "final-data-merger",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "final-data-merger": {
      "main": [
        [
          {
            "node": "final-data-processor",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "final-data-processor": {
      "main": [
        [
          {
            "node": "json-export",
            "type": "main",
            "index": 0
          },
          {
            "node": "excel-export",
            "type": "main",
            "index": 0
          },
          {
            "node": "csv-export",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1",
    "saveManualExecutions": true,
    "callerPolicy": "workflowsFromSameOwner",
    "errorWorkflow": "none"
  },
  "staticData": {},
  "tags": [
    {
      "createdAt": "2025-01-25T00:00:00.000Z",
      "updatedAt": "2025-01-25T00:00:00.000Z",
      "id": "hybrid-scraping",
      "name": "Hybrid Scraping"
    },
    {
      "createdAt": "2025-01-25T00:00:00.000Z", 
      "updatedAt": "2025-01-25T00:00:00.000Z",
      "id": "three-techniques",
      "name": "Three Techniques"
    }
  ],
  "triggerCount": 0,
  "updatedAt": "2025-01-25T00:00:00.000Z",
  "versionId": "1"
}