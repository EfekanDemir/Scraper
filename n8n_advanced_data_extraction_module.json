{
  "active": false,
  "createdAt": "2024-01-20T16:00:00.000Z",
  "id": "advanced_data_extraction_module",
  "name": "Advanced Data Extraction Module",
  "nodes": [
    {
      "parameters": {
        "values": {
          "string": [
            {
              "name": "target_url", 
              "value": "https://example.com/scan-results"
            },
            {
              "name": "extraction_strategy",
              "value": "comprehensive"
            },
            {
              "name": "output_format",
              "value": "excel_multi_sheet"
            },
            {
              "name": "confidence_threshold",
              "value": "0.7"
            },
            {
              "name": "timeout_seconds",
              "value": "30"
            },
            {
              "name": "retry_attempts",
              "value": "3"
            }
          ],
          "boolean": [
            {
              "name": "enable_detailed_extraction",
              "value": true
            },
            {
              "name": "enable_js_extraction", 
              "value": true
            },
            {
              "name": "enable_validation",
              "value": true
            },
            {
              "name": "enable_api_scraping",
              "value": true
            }
          ]
        }
      },
      "id": "extraction_config",
      "name": "Extraction Configuration",
      "type": "n8n-nodes-base.set",
      "typeVersion": 1,
      "position": [200, 300]
    },
    {
      "parameters": {
        "functionCode": "// Session Initialization with Enhanced Structure\nconst config = $input.first().json;\nconst stepStart = Date.now();\n\ntry {\n  console.log('üöÄ Initializing Advanced Data Extraction Session');\n  \n  const session = {\n    session_id: `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,\n    config: config,\n    target_url: config.target_url,\n    start_time: new Date().toISOString(),\n    \n    // Step tracking\n    steps: {\n      session_init: { status: 'completed', timestamp: new Date().toISOString() }\n    },\n    \n    // Error and warning tracking\n    errors: [],\n    warnings: [],\n    \n    // Performance metrics\n    metrics: {\n      session_start: stepStart,\n      steps_completed: 1\n    },\n    \n    // Results structure matching Python project's 7 Excel sheets\n    results: {\n      ozet_bilgiler: [],        // Summary information\n      rakipler: [],             // Competitors\n      sponsorlu_listeler: [],   // Sponsored listings\n      detayli_sonuclar: [],     // Detailed results\n      harita_verileri: [],      // Map data\n      javascript_verileri: [],  // JavaScript data\n      api_verileri: []          // API data\n    },\n    \n    // Data containers\n    html_content: null,\n    extracted_html: null,\n    js_extracted_data: null,\n    api_responses: []\n  };\n  \n  console.log(`‚úÖ Session initialized: ${session.session_id}`);\n  console.log(`üéØ Target URL: ${session.target_url}`);\n  console.log(`üìä Results structure prepared with 7 data categories`);\n  \n  return [{ json: session }];\n  \n} catch (error) {\n  console.error('‚ùå Session Initialization Failed:', error.message);\n  throw error;\n}"
      },
      "id": "session_init",
      "name": "Session Initialization",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [400, 300]
    },
    {
      "parameters": {
        "url": "={{ $json.target_url }}",
        "options": {
          "timeout": 30000,
          "retry": {
            "enabled": true,
            "maxRetries": 3
          },
          "redirect": {
            "followRedirect": true,
            "maxRedirect": 5
          }
        },
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "User-Agent",
              "value": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            },
            {
              "name": "Accept",
              "value": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8"
            },
            {
              "name": "Accept-Language",
              "value": "tr-TR,tr;q=0.9,en;q=0.8"
            }
          ]
        }
      },
      "id": "fetch_html",
      "name": "Fetch HTML Content",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [600, 300]
    },
    {
      "parameters": {
        "functionCode": "// Advanced HTML Content Analysis and Pattern Recognition\nconst session = $input.first().json;\nconst httpResponse = $input.last().json;\n\nconst stepStart = Date.now();\n\ntry {\n  // Ensure session properties exist\n  session.steps = session.steps || {};\n  session.errors = session.errors || [];\n  session.metrics = session.metrics || {};\n  \n  // Update step status\n  session.steps.html_fetch = { status: 'completed', timestamp: new Date().toISOString() };\n  session.steps.content_analysis = { status: 'in_progress', timestamp: new Date().toISOString() };\n  \n  // Extract HTML content with error handling\n  let htmlContent = '';\n  if (httpResponse && httpResponse.body) {\n    htmlContent = httpResponse.body;\n  } else if (httpResponse && httpResponse.data) {\n    htmlContent = httpResponse.data;\n  } else if (typeof httpResponse === 'string') {\n    htmlContent = httpResponse;\n  } else {\n    throw new Error('No HTML content found in response');\n  }\n\n  if (!htmlContent || htmlContent.length < 500) {\n    throw new Error(`Insufficient content for analysis: ${htmlContent.length} characters`);\n  }\n\n  console.log(`üìä HTML Content Size: ${htmlContent.length} characters`);\n\n  // Content Statistics\n  const contentStats = {\n    total_length: htmlContent.length,\n    element_count: (htmlContent.match(/<[^>]+>/g) || []).length,\n    script_count: (htmlContent.match(/<script[^>]*>/gi) || []).length,\n    table_count: (htmlContent.match(/<table[^>]*>/gi) || []).length,\n    form_count: (htmlContent.match(/<form[^>]*>/gi) || []).length,\n    div_count: (htmlContent.match(/<div[^>]*>/gi) || []).length,\n    link_count: (htmlContent.match(/<a[^>]*>/gi) || []).length\n  };\n\n  // Update session with analysis results\n  session.html_content = htmlContent;\n  session.content_stats = contentStats;\n  session.steps.content_analysis = { status: 'completed', timestamp: new Date().toISOString() };\n  session.metrics.processing_time = Date.now() - stepStart;\n\n  console.log('‚úÖ Content Analysis Complete');\n  console.log(`üìä Found ${contentStats.table_count} tables, ${contentStats.script_count} scripts`);\n  console.log(`‚ö° Processing time: ${session.metrics.processing_time}ms`);\n\n  return [{ json: session }];\n\n} catch (error) {\n  // Ensure session.errors exists\n  if (!session.errors) session.errors = [];\n  \n  session.errors.push({\n    step: 'content_analysis',\n    error: error.message,\n    timestamp: new Date().toISOString()\n  });\n  \n  console.error('‚ùå Content Analysis Failed:', error.message);\n  throw error;\n}"
      },
      "id": "content_analysis",
      "name": "Content Analysis & Pattern Recognition",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [800, 300]
    },
    {
      "parameters": {
        "functionCode": "// Enhanced HTML Data Extraction with Specific Pattern Matching\nconst session = $input.first().json;\nconst stepStart = Date.now();\n\ntry {\n  const htmlContent = session.html_content;\n  if (!htmlContent) {\n    throw new Error('No HTML content available for extraction');\n  }\n  \n  console.log(`üîç Starting HTML extraction on ${htmlContent.length} characters`);\n  session.steps.html_extraction = { status: 'in_progress', timestamp: new Date().toISOString() };\n  \n  const extractedData = {\n    all_tables: [],\n    sponsored_listings: [],\n    all_scripts: '',\n    hidden_inputs: [],\n    business_cards: [],\n    search_results: [],\n    meta_data: []\n  };\n  \n  console.log('üéØ Extracting all tables...');\n  // Extract all tables with better pattern matching\n  const allTablesRegex = /<table[^>]*>[\\s\\S]*?<\\/table>/gi;\n  const allTablesMatches = htmlContent.match(allTablesRegex) || [];\n  extractedData.all_tables = allTablesMatches;\n  console.log(`üìä Found ${allTablesMatches.length} total tables`);\n  \n  // Log table samples for debugging\n  allTablesMatches.forEach((table, index) => {\n    const preview = table.substring(0, 200).replace(/\\s+/g, ' ');\n    console.log(`Table ${index + 1} preview: ${preview}...`);\n  });\n  \n  console.log('üéØ Extracting business information divs...');\n  // Extract business information containers\n  const businessInfoRegex = /<div[^>]*class=\"[^\"]*(?:business|company|result|listing)[^\"]*\"[^>]*>[\\s\\S]*?<\\/div>/gi;\n  const businessMatches = htmlContent.match(businessInfoRegex) || [];\n  extractedData.business_cards = businessMatches;\n  console.log(`üè¢ Found ${businessMatches.length} business information containers`);\n  \n  console.log('üéØ Extracting search result containers...');\n  // Extract search result containers\n  const searchResultRegex = /<div[^>]*class=\"[^\"]*(?:search-result|result-item|listing-item)[^\"]*\"[^>]*>[\\s\\S]*?<\\/div>/gi;\n  const searchMatches = htmlContent.match(searchResultRegex) || [];\n  extractedData.search_results = searchMatches;\n  console.log(`üîç Found ${searchMatches.length} search result containers`);\n  \n  console.log('üéØ Extracting sponsored content...');\n  // Extract sponsored content with broader patterns\n  const sponsoredPatterns = [\n    /<div[^>]*class=\"[^\"]*(?:sponsored|ad|promotion|reklam)[^\"]*\"[^>]*>[\\s\\S]*?<\\/div>/gi,\n    /<span[^>]*class=\"[^\"]*sponsored[^\"]*\"[^>]*>[\\s\\S]*?<\\/span>/gi,\n    /<li[^>]*class=\"[^\"]*(?:sponsored|ad)[^\"]*\"[^>]*>[\\s\\S]*?<\\/li>/gi\n  ];\n  \n  sponsoredPatterns.forEach(pattern => {\n    const matches = htmlContent.match(pattern) || [];\n    extractedData.sponsored_listings.push(...matches);\n  });\n  console.log(`üì¢ Found ${extractedData.sponsored_listings.length} sponsored listings`);\n  \n  console.log('üéØ Extracting JavaScript content...');\n  // Extract all script content\n  const scriptRegex = /<script[^>]*>([\\s\\S]*?)<\\/script>/gi;\n  let allScripts = '';\n  let scriptMatch;\n  let scriptCount = 0;\n  while ((scriptMatch = scriptRegex.exec(htmlContent)) !== null) {\n    allScripts += scriptMatch[1] + '\\n';\n    scriptCount++;\n  }\n  extractedData.all_scripts = allScripts;\n  console.log(`üìú Extracted ${scriptCount} scripts with ${allScripts.length} characters total`);\n  \n  console.log('üéØ Extracting hidden inputs...');\n  // Extract hidden input fields with comprehensive patterns\n  const hiddenInputRegex = /<input[^>]*type=[\"']hidden[\"'][^>]*>/gi;\n  const hiddenInputMatches = htmlContent.match(hiddenInputRegex) || [];\n  hiddenInputMatches.forEach(inputHtml => {\n    const nameMatch = inputHtml.match(/name=[\"']([^\"']+)[\"']/i);\n    const valueMatch = inputHtml.match(/value=[\"']([^\"']*)[\"']/i);\n    const idMatch = inputHtml.match(/id=[\"']([^\"']+)[\"']/i);\n    \n    if (nameMatch || idMatch) {\n      extractedData.hidden_inputs.push({\n        name: nameMatch ? nameMatch[1] : '',\n        id: idMatch ? idMatch[1] : '',\n        value: valueMatch ? valueMatch[1] : ''\n      });\n    }\n  });\n  console.log(`üîí Found ${extractedData.hidden_inputs.length} hidden input fields`);\n  \n  // Log hidden inputs for debugging\n  extractedData.hidden_inputs.forEach(input => {\n    console.log(`Hidden input: ${input.name} = ${input.value}`);\n  });\n  \n  console.log('üéØ Extracting meta data...');\n  // Extract meta data and page info\n  const metaRegex = /<meta[^>]*>/gi;\n  const metaMatches = htmlContent.match(metaRegex) || [];\n  metaMatches.forEach(metaHtml => {\n    const nameMatch = metaHtml.match(/name=[\"']([^\"']+)[\"']/i);\n    const contentMatch = metaHtml.match(/content=[\"']([^\"']*)[\"']/i);\n    const propertyMatch = metaHtml.match(/property=[\"']([^\"']+)[\"']/i);\n    \n    if ((nameMatch || propertyMatch) && contentMatch) {\n      extractedData.meta_data.push({\n        name: nameMatch ? nameMatch[1] : (propertyMatch ? propertyMatch[1] : ''),\n        content: contentMatch[1]\n      });\n    }\n  });\n  \n  session.extracted_html = extractedData;\n  session.steps.html_extraction = { status: 'completed', timestamp: new Date().toISOString() };\n  session.metrics.extraction_time = Date.now() - stepStart;\n  \n  console.log('‚úÖ Enhanced HTML Data Extraction Complete');\n  console.log(`üìä Extraction Summary:`);\n  console.log(`  ‚Ä¢ Tables: ${extractedData.all_tables.length}`);\n  console.log(`  ‚Ä¢ Business cards: ${extractedData.business_cards.length}`);\n  console.log(`  ‚Ä¢ Search results: ${extractedData.search_results.length}`);\n  console.log(`  ‚Ä¢ Sponsored listings: ${extractedData.sponsored_listings.length}`);\n  console.log(`  ‚Ä¢ Hidden inputs: ${extractedData.hidden_inputs.length}`);\n  console.log(`  ‚Ä¢ JavaScript chars: ${extractedData.all_scripts.length}`);\n  console.log(`‚ö° Extraction time: ${session.metrics.extraction_time}ms`);\n  \n  return [{ json: session }];\n  \n} catch (error) {\n  session.errors.push({\n    step: 'html_extraction',\n    error: error.message,\n    timestamp: new Date().toISOString()\n  });\n  \n  console.error('‚ùå HTML Extraction Failed:', error.message);\n  throw error;\n}"
      },
      "id": "html_extraction",
      "name": "HTML Data Extraction",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [1000, 300]
    },
    {
      "parameters": {
        "functionCode": "// Advanced Data Processing & Assembly with Improved HTML Parsing\nconst session = $input.first().json;\nconst stepStart = Date.now();\n\ntry {\n  console.log('üîÑ Starting Advanced Data Processing...');\n  \n  session.steps.data_processing = { status: 'in_progress', timestamp: new Date().toISOString() };\n  \n  const extractedHtml = session.extracted_html;\n  const htmlContent = session.html_content;\n  \n  // Enhanced Table Processing Function for specific HTML structures\n  function processTableData(tableHtml, tableIndex) {\n    if (!tableHtml) return [];\n    \n    const results = [];\n    \n    try {\n      console.log(`üîç Processing table ${tableIndex + 1}`);\n      \n      // Clean HTML and extract text content better\n      const cleanHtml = tableHtml.replace(/\\s+/g, ' ').trim();\n      \n      // Extract table rows with improved regex\n      const rowRegex = /<tr[^>]*>([\\s\\S]*?)<\\/tr>/gis;\n      const rowMatches = cleanHtml.match(rowRegex) || [];\n      \n      console.log(`  Found ${rowMatches.length} rows`);\n      \n      rowMatches.forEach((rowHtml, rowIndex) => {\n        // Extract cells with better handling of th and td, including colspan\n        const cellRegex = /<t[hd][^>]*>([\\s\\S]*?)<\\/t[hd]>/gis;\n        const cellMatches = rowHtml.match(cellRegex) || [];\n        \n        if (cellMatches.length >= 1) {\n          const rowData = {};\n          let hasValidData = false;\n          \n          cellMatches.forEach((cellHtml, cellIndex) => {\n            // Extract text more thoroughly\n            let cellText = cellHtml\n              .replace(/<t[hd][^>]*>|<\\/t[hd]>/gi, '')\n              .replace(/<br\\s*\\/?>/gi, ' ')\n              .replace(/<[^>]*>/g, '')\n              .replace(/&nbsp;/g, ' ')\n              .replace(/&amp;/g, '&')\n              .replace(/&lt;/g, '<')\n              .replace(/&gt;/g, '>')\n              .replace(/&quot;/g, '\"')\n              .replace(/&#39;/g, \"'\")\n              .replace(/\\s+/g, ' ')\n              .trim();\n            \n            if (cellText && cellText.length > 0 && cellText !== '-' && cellText !== '‚Äî' && cellText !== '...' && cellText !== 'N/A') {\n              // Smart column detection based on content and position\n              let columnName = `col_${cellIndex}`;\n              \n              // Pattern matching for Turkish and English content\n              const textLower = cellText.toLowerCase();\n              \n              if (textLower.includes('i≈ületme') || textLower.includes('business') || textLower.includes('name') || textLower.includes('ad:')) {\n                columnName = 'business_name';\n              } else if (textLower.includes('adres') || textLower.includes('address') || textLower.includes('konum') || textLower.includes('location')) {\n                columnName = 'address';\n              } else if (textLower.includes('telefon') || textLower.includes('phone') || /\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}/.test(cellText)) {\n                columnName = 'phone';\n              } else if (textLower.includes('website') || textLower.includes('web') || cellText.includes('www.') || cellText.includes('http')) {\n                columnName = 'website';\n              } else if (textLower.includes('sƒ±ra') || textLower.includes('rank') || textLower.includes('position') || textLower.includes('#')) {\n                columnName = 'rank';\n              } else if (textLower.includes('puan') || textLower.includes('score') || textLower.includes('rating')) {\n                columnName = 'score';\n              } else if (textLower.includes('kategori') || textLower.includes('category') || textLower.includes('type')) {\n                columnName = 'category';\n              } else if (textLower.includes('mesafe') || textLower.includes('distance') || textLower.includes('km') || textLower.includes('mile')) {\n                columnName = 'distance';\n              } else if (textLower.includes('toplam') || textLower.includes('total') || textLower.includes('sum')) {\n                columnName = 'total';\n              } else if (textLower.includes('rakip') || textLower.includes('competitor')) {\n                columnName = 'competitor_info';\n              } else if (textLower.includes('tarama') || textLower.includes('scan')) {\n                columnName = 'scan_info';\n              }\n              \n              // Handle numeric data\n              if (/^#?\\d+$/.test(cellText)) {\n                rowData[columnName] = parseInt(cellText.replace('#', ''));\n              } else if (/^\\d+[.,]\\d+$/.test(cellText)) {\n                rowData[columnName] = parseFloat(cellText.replace(',', '.'));\n              } else {\n                rowData[columnName] = cellText;\n              }\n              \n              hasValidData = true;\n            }\n          });\n          \n          if (hasValidData && Object.keys(rowData).length > 0) {\n            results.push({\n              table_index: tableIndex,\n              row_index: rowIndex,\n              data: rowData,\n              is_header: rowIndex === 0 && (JSON.stringify(rowData).toLowerCase().includes('total') || JSON.stringify(rowData).toLowerCase().includes('toplam')),\n              cell_count: cellMatches.length,\n              raw_html: rowHtml.substring(0, 300)\n            });\n          }\n        }\n      });\n      \n    } catch (e) {\n      console.warn(`Error processing table ${tableIndex}:`, e.message);\n    }\n    \n    return results;\n  }\n  \n  // Enhanced JavaScript Data Extraction\n  function extractJavaScriptData(scriptContent) {\n    const jsData = {\n      scan_guid: null,\n      place_id: null,\n      keyword_id: null,\n      keyword_guid: null,\n      pinz: [],\n      api_endpoints: [],\n      config_data: {},\n      dynamic_urls: [],\n      variables: []\n    };\n    \n    if (!scriptContent) return jsData;\n    \n    console.log('üîç Extracting JavaScript variables...');\n    \n    try {\n      // Extract scan_guid with multiple patterns\n      const scanGuidPatterns = [\n        /scan_guid[\"']?\\s*[:=]\\s*[\"']([^\"']+)[\"']/gi,\n        /[\"']scan_guid[\"']\\s*[:=]\\s*[\"']([^\"']+)[\"']/gi,\n        /scanGuid[\"']?\\s*[:=]\\s*[\"']([^\"']+)[\"']/gi,\n        /value=[\"']scan_guid[\"'][^>]*value=[\"']([^\"']+)[\"']/gi\n      ];\n      \n      scanGuidPatterns.forEach(pattern => {\n        const matches = scriptContent.match(pattern);\n        if (matches && !jsData.scan_guid) {\n          matches.forEach(match => {\n            const valueMatch = match.match(/[\"']([a-f0-9\\-]{36}|[a-f0-9\\-]{32}|[a-f0-9\\-]{20,})[\"']/i);\n            if (valueMatch) {\n              jsData.scan_guid = valueMatch[1];\n              console.log(`Found scan_guid: ${jsData.scan_guid}`);\n            }\n          });\n        }\n      });\n      \n      // Extract place_id from hidden inputs and JavaScript\n      const placeIdPatterns = [\n        /place_id[\"']?\\s*[:=]\\s*[\"']([^\"']+)[\"']/gi,\n        /[\"']place_id[\"']\\s*[:=]\\s*[\"']([^\"']+)[\"']/gi,\n        /placeId[\"']?\\s*[:=]\\s*[\"']([^\"']+)[\"']/gi,\n        /name=[\"']place_id[\"'][^>]*value=[\"']([^\"']+)[\"']/gi\n      ];\n      \n      placeIdPatterns.forEach(pattern => {\n        const matches = scriptContent.match(pattern);\n        if (matches && !jsData.place_id) {\n          matches.forEach(match => {\n            const valueMatch = match.match(/[\"']([^\"']+)[\"']/);\n            if (valueMatch && valueMatch[1].length > 5) {\n              jsData.place_id = valueMatch[1];\n              console.log(`Found place_id: ${jsData.place_id}`);\n            }\n          });\n        }\n      });\n      \n      // Extract keyword_id and keyword_guid\n      const keywordIdMatch = scriptContent.match(/keyword_id[\"']?\\s*[:=]\\s*[\"']([^\"']+)[\"']/gi);\n      if (keywordIdMatch) {\n        const valueMatch = keywordIdMatch[0].match(/[\"']([^\"']+)[\"']/);\n        if (valueMatch) {\n          jsData.keyword_id = valueMatch[1];\n          console.log(`Found keyword_id: ${jsData.keyword_id}`);\n        }\n      }\n      \n      const keywordGuidMatch = scriptContent.match(/keyword_guid[\"']?\\s*[:=]\\s*[\"']([^\"']+)[\"']/gi);\n      if (keywordGuidMatch) {\n        const valueMatch = keywordGuidMatch[0].match(/[\"']([^\"']+)[\"']/);\n        if (valueMatch) {\n          jsData.keyword_guid = valueMatch[1];\n          console.log(`Found keyword_guid: ${jsData.keyword_guid}`);\n        }\n      }\n      \n      // Extract pinz array with better error handling\n      const pinzPatterns = [\n        /var\\s+pinz\\s*=\\s*(\\[.*?\\]);/gs,\n        /pinz\\s*=\\s*(\\[.*?\\]);/gs,\n        /[\"']pinz[\"']\\s*:\\s*(\\[.*?\\])/gs\n      ];\n      \n      pinzPatterns.forEach(pattern => {\n        const matches = scriptContent.match(pattern);\n        if (matches && jsData.pinz.length === 0) {\n          matches.forEach(match => {\n            try {\n              const arrayMatch = match.match(/\\[.*?\\]/s);\n              if (arrayMatch) {\n                const pinzArray = JSON.parse(arrayMatch[0]);\n                if (Array.isArray(pinzArray) && pinzArray.length > 0) {\n                  jsData.pinz = pinzArray;\n                  console.log(`Found pinz array with ${pinzArray.length} items`);\n                }\n              }\n            } catch (e) {\n              console.warn('Failed to parse pinz array:', e.message);\n            }\n          });\n        }\n      });\n      \n      // Extract API endpoints with comprehensive patterns\n      const apiPatterns = [\n        /[\"']([^\"']*\\/api\\/[^\"']*)[\"']/gi,\n        /[\"']([^\"']*\\/analytics\\/[^\"']*)[\"']/gi,\n        /[\"']([^\"']*\\/competitors[^\"']*)[\"']/gi,\n        /[\"']([^\"']*\\/scans?\\/[^\"']*)[\"']/gi,\n        /[\"']([^\"']*\\/data[^\"']*)[\"']/gi,\n        /[\"']([^\"']*\\/search[^\"']*)[\"']/gi,\n        /[\"']([^\"']*\\/reports?[^\"']*)[\"']/gi,\n        /[\"']([^\"']*\\/export[^\"']*)[\"']/gi,\n        /url\\s*:\\s*[\"']([^\"']+)[\"']/gi,\n        /endpoint\\s*:\\s*[\"']([^\"']+)[\"']/gi\n      ];\n      \n      apiPatterns.forEach(pattern => {\n        const matches = scriptContent.match(pattern) || [];\n        matches.forEach(match => {\n          const urlMatch = match.match(/[\"']([^\"']+)[\"']/);\n          if (urlMatch) {\n            const url = urlMatch[1];\n            if (url && url.length > 5 && !jsData.api_endpoints.includes(url)) {\n              // Filter out non-API URLs\n              if (url.includes('/api/') || url.includes('/data/') || url.includes('/analytics/') ||\n                  url.includes('/scan') || url.includes('/report') || url.includes('/export') ||\n                  url.includes('/competitor')) {\n                jsData.api_endpoints.push(url);\n                console.log(`Found API endpoint: ${url}`);\n              }\n            }\n          }\n        });\n      });\n      \n      // Extract all JavaScript variables for analysis\n      const variablePatterns = [\n        /var\\s+(\\w+)\\s*=\\s*([^;]+);/gi,\n        /let\\s+(\\w+)\\s*=\\s*([^;]+);/gi,\n        /const\\s+(\\w+)\\s*=\\s*([^;]+);/gi,\n        /(\\w+)\\s*:\\s*([^,}]+)/gi\n      ];\n      \n      variablePatterns.forEach(pattern => {\n        let match;\n        while ((match = pattern.exec(scriptContent)) !== null) {\n          const varName = match[1];\n          const varValue = match[2].trim();\n          \n          if (varName && varValue && varValue.length < 200) {\n            jsData.variables.push({\n              name: varName,\n              value: varValue.replace(/[\"']/g, ''),\n              type: typeof varValue\n            });\n          }\n        }\n      });\n      \n    } catch (e) {\n      console.warn('Error in JavaScript extraction:', e.message);\n    }\n    \n    console.log(`üîç JavaScript extraction complete:`);\n    console.log(`  ‚Ä¢ scan_guid: ${jsData.scan_guid ? 'Found' : 'Not found'}`);\n    console.log(`  ‚Ä¢ place_id: ${jsData.place_id ? 'Found' : 'Not found'}`);\n    console.log(`  ‚Ä¢ pinz array: ${jsData.pinz.length} items`);\n    console.log(`  ‚Ä¢ API endpoints: ${jsData.api_endpoints.length} found`);\n    console.log(`  ‚Ä¢ Variables: ${jsData.variables.length} found`);\n    \n    return jsData;\n  }\n  \n  // Process extracted data into the 7 Excel sheet categories\n  console.log('üîÑ Processing data into 7 categories...');\n  \n  // 1. ozet_bilgiler (Summary Information)\n  console.log('üìã Processing summary information...');\n  if (extractedHtml.all_tables && extractedHtml.all_tables.length > 0) {\n    extractedHtml.all_tables.forEach((table, tableIndex) => {\n      const tableRows = processTableData(table, tableIndex);\n      \n      tableRows.forEach(row => {\n        // Look for summary/overview type data\n        const rowText = JSON.stringify(row.data).toLowerCase();\n        \n        if (rowText.includes('toplam') || rowText.includes('total') || \n            rowText.includes('√∂zet') || rowText.includes('summary') ||\n            rowText.includes('tarama') || rowText.includes('scan') ||\n            row.is_header || tableIndex === 0) {\n          \n          session.results.ozet_bilgiler.push({\n            table_source: tableIndex,\n            data_type: 'summary_table',\n            ...row.data\n          });\n        }\n      });\n    });\n    console.log(`üìã Processed ${session.results.ozet_bilgiler.length} summary entries`);\n  }\n  \n  // 2. rakipler (Competitors)\n  console.log('üè¢ Processing competitors...');\n  if (extractedHtml.all_tables) {\n    extractedHtml.all_tables.forEach((table, tableIndex) => {\n      const tableRows = processTableData(table, tableIndex);\n      \n      tableRows.forEach(row => {\n        if (!row.is_header && Object.keys(row.data).length > 1) {\n          const rowText = JSON.stringify(row.data).toLowerCase();\n          \n          // Check if this looks like competitor/business data\n          if (rowText.includes('business') || rowText.includes('company') ||\n              rowText.includes('i≈ületme') || rowText.includes('firma') ||\n              row.data.business_name || row.data.address || row.data.phone ||\n              Object.keys(row.data).length >= 3) {\n            \n            session.results.rakipler.push({\n              table_source: tableIndex,\n              rank: row.data.rank || row.row_index,\n              business_name: row.data.business_name || Object.values(row.data)[0] || 'Unknown',\n              address: row.data.address || '',\n              phone: row.data.phone || '',\n              website: row.data.website || '',\n              score: row.data.score || '',\n              category: row.data.category || '',\n              distance: row.data.distance || '',\n              ...row.data\n            });\n          }\n        }\n      });\n    });\n    console.log(`üè¢ Processed ${session.results.rakipler.length} competitor entries`);\n  }\n  \n  // 3. sponsorlu_listeler (Sponsored Listings)\n  console.log('üì¢ Processing sponsored listings...');\n  if (extractedHtml.sponsored_listings && extractedHtml.sponsored_listings.length > 0) {\n    extractedHtml.sponsored_listings.forEach((sponsoredHtml, index) => {\n      const sponsoredText = sponsoredHtml.replace(/<[^>]*>/g, '').trim();\n      if (sponsoredText.length > 10) {\n        session.results.sponsorlu_listeler.push({\n          index: index + 1,\n          content: sponsoredText,\n          html_snippet: sponsoredHtml.substring(0, 200) + '...'\n        });\n      }\n    });\n    console.log(`üì¢ Processed ${session.results.sponsorlu_listeler.length} sponsored listings`);\n  }\n  \n  // 4. detayli_sonuclar (Detailed Results)\n  console.log('üìä Processing detailed results...');\n  if (extractedHtml.all_tables) {\n    extractedHtml.all_tables.forEach((table, tableIndex) => {\n      const tableRows = processTableData(table, tableIndex);\n      \n      tableRows.forEach(row => {\n        if (!row.is_header && Object.keys(row.data).length >= 2) {\n          session.results.detayli_sonuclar.push({\n            table_index: tableIndex,\n            row_index: row.row_index,\n            data_fields: Object.keys(row.data).length,\n            source: 'html_table',\n            ...row.data\n          });\n        }\n      });\n    });\n    console.log(`üìä Processed ${session.results.detayli_sonuclar.length} detailed result entries`);\n  }\n  \n  // 5. harita_verileri (Map Data)\n  console.log('üó∫Ô∏è Processing map data...');\n  if (extractedHtml.hidden_inputs) {\n    extractedHtml.hidden_inputs.forEach(input => {\n      if (input.name && (input.name.toLowerCase().includes('lat') || input.name.toLowerCase().includes('lng') ||\n          input.name.toLowerCase().includes('coord') || input.name.toLowerCase().includes('location') ||\n          input.name.toLowerCase().includes('place') || input.name.toLowerCase().includes('map'))) {\n        session.results.harita_verileri.push({\n          field_name: input.name,\n          field_value: input.value,\n          data_type: 'hidden_input',\n          source: 'html_form'\n        });\n      }\n    });\n  }\n  \n  // Extract location data from meta tags\n  if (extractedHtml.meta_data) {\n    extractedHtml.meta_data.forEach(meta => {\n      if (meta.name && (meta.name.toLowerCase().includes('geo') || meta.name.toLowerCase().includes('location'))) {\n        session.results.harita_verileri.push({\n          field_name: meta.name,\n          field_value: meta.content,\n          data_type: 'meta_tag',\n          source: 'html_meta'\n        });\n      }\n    });\n  }\n  console.log(`üó∫Ô∏è Processed ${session.results.harita_verileri.length} map data entries`);\n  \n  // 6. javascript_verileri (JavaScript Data)\n  console.log('üìú Processing JavaScript data...');\n  if (extractedHtml.all_scripts) {\n    const jsData = extractJavaScriptData(extractedHtml.all_scripts);\n    \n    // Store extracted JavaScript variables\n    if (jsData.scan_guid) {\n      session.results.javascript_verileri.push({\n        variable: 'scan_guid',\n        value: jsData.scan_guid,\n        data_type: 'string',\n        source: 'javascript'\n      });\n    }\n    \n    if (jsData.place_id) {\n      session.results.javascript_verileri.push({\n        variable: 'place_id',\n        value: jsData.place_id,\n        data_type: 'string',\n        source: 'javascript'\n      });\n    }\n    \n    if (jsData.keyword_id) {\n      session.results.javascript_verileri.push({\n        variable: 'keyword_id',\n        value: jsData.keyword_id,\n        data_type: 'string',\n        source: 'javascript'\n      });\n    }\n    \n    if (jsData.keyword_guid) {\n      session.results.javascript_verileri.push({\n        variable: 'keyword_guid',\n        value: jsData.keyword_guid,\n        data_type: 'string',\n        source: 'javascript'\n      });\n    }\n    \n    if (jsData.pinz && jsData.pinz.length > 0) {\n      session.results.javascript_verileri.push({\n        variable: 'pinz',\n        value: JSON.stringify(jsData.pinz),\n        data_type: 'array',\n        length: jsData.pinz.length,\n        source: 'javascript'\n      });\n    }\n    \n    // Store API endpoints for scraping\n    if (jsData.api_endpoints && jsData.api_endpoints.length > 0) {\n      jsData.api_endpoints.forEach((endpoint, index) => {\n        session.results.javascript_verileri.push({\n          variable: `api_endpoint_${index + 1}`,\n          value: endpoint,\n          data_type: 'url',\n          source: 'javascript'\n        });\n      });\n    }\n    \n    // Store other variables\n    if (jsData.variables && jsData.variables.length > 0) {\n      jsData.variables.slice(0, 20).forEach(variable => { // Limit to first 20 variables\n        session.results.javascript_verileri.push({\n          variable: variable.name,\n          value: variable.value,\n          data_type: variable.type,\n          source: 'javascript_variable'\n        });\n      });\n    }\n    \n    // Store extracted JavaScript data for API scraping\n    session.js_extracted_data = jsData;\n    \n    console.log(`üìú Processed ${session.results.javascript_verileri.length} JavaScript data entries`);\n  }\n  \n  // Add data from hidden inputs to JavaScript data\n  if (extractedHtml.hidden_inputs) {\n    extractedHtml.hidden_inputs.forEach(input => {\n      if (input.name && input.value) {\n        session.results.javascript_verileri.push({\n          variable: input.name,\n          value: input.value,\n          data_type: 'hidden_input',\n          source: 'html_form'\n        });\n      }\n    });\n  }\n  \n  // 7. api_verileri (API Data) - Initialize for next step\n  session.results.api_verileri = [];\n  \n  // Add summary message if no data found in any category\n  const categories = ['ozet_bilgiler', 'rakipler', 'sponsorlu_listeler', 'detayli_sonuclar', 'harita_verileri', 'javascript_verileri'];\n  categories.forEach(category => {\n    if (session.results[category].length === 0) {\n      session.results[category].push({\n        message: `No ${category.replace('_', ' ')} found`,\n        timestamp: new Date().toISOString(),\n        debug_info: {\n          tables_processed: extractedHtml.all_tables ? extractedHtml.all_tables.length : 0,\n          scripts_processed: extractedHtml.all_scripts ? extractedHtml.all_scripts.length : 0,\n          hidden_inputs_found: extractedHtml.hidden_inputs ? extractedHtml.hidden_inputs.length : 0\n        }\n      });\n    }\n  });\n  \n  // Calculate data quality metrics\n  const totalExtracted = Object.values(session.results).reduce((sum, arr) => sum + arr.length, 0);\n  const qualityScore = Math.min(100, totalExtracted * 2);\n  \n  session.steps.data_processing = { status: 'completed', timestamp: new Date().toISOString() };\n  session.metrics.total_extracted = totalExtracted;\n  session.metrics.quality_score = qualityScore;\n  session.metrics.processing_time = Date.now() - stepStart;\n  \n  console.log('‚úÖ Advanced Data Processing Complete!');\n  console.log(`üìä Data Summary:`);\n  console.log(`  ‚Ä¢ ozet_bilgiler: ${session.results.ozet_bilgiler.length} entries`);\n  console.log(`  ‚Ä¢ rakipler: ${session.results.rakipler.length} entries`);\n  console.log(`  ‚Ä¢ sponsorlu_listeler: ${session.results.sponsorlu_listeler.length} entries`);\n  console.log(`  ‚Ä¢ detayli_sonuclar: ${session.results.detayli_sonuclar.length} entries`);\n  console.log(`  ‚Ä¢ harita_verileri: ${session.results.harita_verileri.length} entries`);\n  console.log(`  ‚Ä¢ javascript_verileri: ${session.results.javascript_verileri.length} entries`);\n  console.log(`üìà Quality Score: ${qualityScore}/100`);\n  console.log(`‚ö° Processing time: ${session.metrics.processing_time}ms`);\n  \n  return [{ json: session }];\n  \n} catch (error) {\n  session.errors.push({\n    step: 'data_processing',\n    error: error.message,\n    timestamp: new Date().toISOString()\n  });\n  \n  console.error('‚ùå Data Processing Failed:', error.message);\n  throw error;\n}"
      },
      "id": "data_processing",
      "name": "Data Processing & Assembly",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [1200, 300]
    },
    {
      "parameters": {
        "functionCode": "// Dynamic API Endpoint Scraping\nconst session = $input.first().json;\nconst stepStart = Date.now();\n\ntry {\n  console.log('üöÄ Starting Dynamic API Scraping...');\n  \n  session.steps.api_scraping = { status: 'in_progress', timestamp: new Date().toISOString() };\n  \n  const jsData = session.js_extracted_data;\n  const apiEndpoints = jsData?.api_endpoints || [];\n  \n  if (apiEndpoints.length === 0) {\n    console.log('‚ö†Ô∏è No API endpoints found to scrape');\n    session.results.api_verileri.push({\n      message: 'No API endpoints found',\n      timestamp: new Date().toISOString(),\n      debug_info: {\n        javascript_data_available: !!jsData,\n        scan_guid: jsData?.scan_guid || 'not found',\n        place_id: jsData?.place_id || 'not found'\n      }\n    });\n    \n    session.steps.api_scraping = { status: 'completed', timestamp: new Date().toISOString() };\n    return [{ json: session }];\n  }\n  \n  console.log(`üéØ Found ${apiEndpoints.length} API endpoints to scrape`);\n  \n  // Build API requests with dynamic parameters\n  const apiRequests = [];\n  const baseParams = {\n    scan_guid: jsData.scan_guid,\n    place_id: jsData.place_id,\n    keyword_id: jsData.keyword_id,\n    keyword_guid: jsData.keyword_guid\n  };\n  \n  apiEndpoints.forEach((endpoint, index) => {\n    try {\n      // Build full URL with parameters\n      let fullUrl = endpoint;\n      \n      // Add parameters to URL\n      const urlParams = new URLSearchParams();\n      Object.entries(baseParams).forEach(([key, value]) => {\n        if (value) {\n          urlParams.append(key, value);\n        }\n      });\n      \n      if (urlParams.toString()) {\n        fullUrl += (endpoint.includes('?') ? '&' : '?') + urlParams.toString();\n      }\n      \n      apiRequests.push({\n        index: index + 1,\n        endpoint: endpoint,\n        full_url: fullUrl,\n        method: 'GET',\n        expected_data: 'json'\n      });\n      \n    } catch (e) {\n      console.warn(`Error building API request for endpoint ${index + 1}:`, e.message);\n    }\n  });\n  \n  // Store API request information for manual execution or next workflow step\n  session.results.api_verileri = session.results.api_verileri || [];\n  \n  apiRequests.forEach(request => {\n    session.results.api_verileri.push({\n      api_request_index: request.index,\n      endpoint: request.endpoint,\n      full_url: request.full_url,\n      method: request.method,\n      status: 'prepared',\n      timestamp: new Date().toISOString(),\n      parameters: baseParams\n    });\n  });\n  \n  // Store API requests for potential execution\n  session.api_requests = apiRequests;\n  \n  session.steps.api_scraping = { status: 'completed', timestamp: new Date().toISOString() };\n  session.metrics.api_requests_prepared = apiRequests.length;\n  session.metrics.api_processing_time = Date.now() - stepStart;\n  \n  console.log('‚úÖ Dynamic API Scraping Preparation Complete!');\n  console.log(`üîó Prepared ${apiRequests.length} API requests`);\n  console.log(`‚ö° Processing time: ${session.metrics.api_processing_time}ms`);\n  \n  // Log the API requests for debugging\n  apiRequests.forEach(request => {\n    console.log(`API ${request.index}: ${request.full_url}`);\n  });\n  \n  return [{ json: session }];\n  \n} catch (error) {\n  session.errors.push({\n    step: 'api_scraping',\n    error: error.message,\n    timestamp: new Date().toISOString()\n  });\n  \n  console.error('‚ùå API Scraping Failed:', error.message);\n  throw error;\n}"
      },
      "id": "api_scraping",
      "name": "Dynamic API Scraping",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [1400, 300]
    },
    {
      "parameters": {
        "functionCode": "// Excel Multi-Sheet Export Preparation\nconst session = $input.first().json;\nconst stepStart = Date.now();\n\ntry {\n  console.log('üìä Starting Excel Multi-Sheet Export Preparation...');\n  \n  session.steps.excel_export = { status: 'in_progress', timestamp: new Date().toISOString() };\n  \n  const excelData = {\n    metadata: {\n      session_id: session.session_id,\n      target_url: session.target_url,\n      extraction_timestamp: new Date().toISOString(),\n      total_extracted: session.metrics.total_extracted,\n      quality_score: session.metrics.quality_score,\n      processing_time: session.metrics.processing_time\n    },\n    sheets: {}\n  };\n  \n  // Prepare each sheet data\n  const sheets = [\n    { name: 'ozet_bilgiler', title: '√ñzet Bilgiler' },\n    { name: 'rakipler', title: 'Rakipler' },\n    { name: 'sponsorlu_listeler', title: 'Sponsorlu Listeler' },\n    { name: 'detayli_sonuclar', title: 'Detaylƒ± Sonu√ßlar' },\n    { name: 'harita_verileri', title: 'Harita Verileri' },\n    { name: 'javascript_verileri', title: 'JavaScript Verileri' },\n    { name: 'api_verileri', title: 'API Verileri' }\n  ];\n  \n  sheets.forEach(sheet => {\n    const sheetData = session.results[sheet.name] || [];\n    \n    console.log(`üìã Preparing ${sheet.title} sheet with ${sheetData.length} rows`);\n    \n    // Convert data to CSV format for Excel compatibility\n    const csvRows = [];\n    \n    if (sheetData.length > 0) {\n      // Get all unique keys for headers\n      const allKeys = new Set();\n      sheetData.forEach(row => {\n        Object.keys(row).forEach(key => allKeys.add(key));\n      });\n      \n      const headers = Array.from(allKeys);\n      csvRows.push(headers.join(','));\n      \n      // Add data rows\n      sheetData.forEach(row => {\n        const csvRow = headers.map(header => {\n          const value = row[header] || '';\n          // Escape CSV values\n          const stringValue = typeof value === 'object' ? JSON.stringify(value) : String(value);\n          return `\"${stringValue.replace(/\"/g, '\"\"')}\"`;\n        });\n        csvRows.push(csvRow.join(','));\n      });\n    } else {\n      csvRows.push('message');\n      csvRows.push('\"No data found\"');\n    }\n    \n    excelData.sheets[sheet.name] = {\n      title: sheet.title,\n      csv_data: csvRows.join('\\n'),\n      row_count: sheetData.length,\n      column_count: csvRows.length > 0 ? csvRows[0].split(',').length : 0\n    };\n  });\n  \n  // Store Excel data in session\n  session.excel_export_data = excelData;\n  \n  session.steps.excel_export = { status: 'completed', timestamp: new Date().toISOString() };\n  session.metrics.excel_export_time = Date.now() - stepStart;\n  \n  console.log('‚úÖ Excel Multi-Sheet Export Preparation Complete!');\n  console.log(`üìä Export Summary:`);\n  Object.entries(excelData.sheets).forEach(([sheetName, sheetInfo]) => {\n    console.log(`  ‚Ä¢ ${sheetInfo.title}: ${sheetInfo.row_count} rows, ${sheetInfo.column_count} columns`);\n  });\n  console.log(`‚ö° Export preparation time: ${session.metrics.excel_export_time}ms`);\n  \n  return [{ json: session }];\n  \n} catch (error) {\n  session.errors.push({\n    step: 'excel_export',\n    error: error.message,\n    timestamp: new Date().toISOString()\n  });\n  \n  console.error('‚ùå Excel Export Preparation Failed:', error.message);\n  throw error;\n}"
      },
      "id": "excel_export",
      "name": "Excel Multi-Sheet Export",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [1600, 300]
    }
  ],
  "connections": {
    "Extraction Configuration": {
      "main": [
        [
          {
            "node": "Session Initialization",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Session Initialization": {
      "main": [
        [
          {
            "node": "Fetch HTML Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch HTML Content": {
      "main": [
        [
          {
            "node": "Content Analysis & Pattern Recognition",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Content Analysis & Pattern Recognition": {
      "main": [
        [
          {
            "node": "HTML Data Extraction",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "HTML Data Extraction": {
      "main": [
        [
          {
            "node": "Data Processing & Assembly",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Data Processing & Assembly": {
      "main": [
        [
          {
            "node": "Dynamic API Scraping",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Dynamic API Scraping": {
      "main": [
        [
          {
            "node": "Excel Multi-Sheet Export",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "settings": {},
  "staticData": {},
  "tags": [],
  "triggerCount": 0,
  "updatedAt": "2024-01-20T16:30:00.000Z",
  "versionId": "v2.0"
}