# Web Scraping Projesi - Tamamlanan Ã–zellikler

## ğŸ“‹ Proje Ã–zeti

Bu proje, belirtilen URL'den (`https://www.local-rank.report/scan/97919fde-e478-4081-983f-7e0065b6b5bb`) veri Ã§ekmek iÃ§in tasarlanmÄ±ÅŸ kapsamlÄ± bir Python web scraping scriptidir.

## âœ… Tamamlanan Ã–zellikler

### 1. **Ana Veri Ã‡ekme FonksiyonlarÄ±**

#### A. `scrape_ozet_bilgiler(soup)` âœ…
- **Scan Information Tablosu** verilerini Ã§eker:
  - Ä°ÅŸletme AdÄ± (`span.bizname`)
  - Adres (`span.center-block`)
  - Yorum SayÄ±sÄ± (`div.rating-container + span`)
  - Anahtar Kelime ve Dil (Keyword iÃ§eren td'nin kardeÅŸ td'si)
  - Tarih (`td.cnv_dt_lcl`)

- **Rank Summary Tablosu** verilerini Ã§eker:
  - Her satÄ±rdaki ilk ve ikinci td'leri anahtar-deÄŸer Ã§ifti olarak alÄ±r
  - Dictionary formatÄ±nda dÃ¶ndÃ¼rÃ¼r

#### B. `scrape_rakipler(soup)` âœ…
- **table#tbl_comp_rank** iÃ§indeki tÃ¼m rakip verilerini Ã§eker:
  - Ä°sim (`a.ext`)
  - Puan/Yorum (`div.rating-container + span`)
  - Adres (`i.fa-map-marker` iÃ§eren `span.center-block`)
  - Kategoriler ("Categories:" iÃ§eren `p` etiketi)
  - Web Sitesi (`i.fa-globe` iÃ§eren `span > a` href)
  - FotoÄŸraf SayÄ±sÄ± (`i.fa-photo` iÃ§eren `span`)
  - Sahiplenme Durumu ("Claimed"/"Un Claimed" iÃ§eren `span`)
  - BulunduÄŸu Konum SayÄ±sÄ± (`td.text-center > h5`)
  - Ortalama SÄ±ralama (AR) (`span.dotlg2`)

#### C. `scrape_sponsorlu_listeler(soup)` âœ…
- **table#tbl_ads_rank** iÃ§indeki sponsorlu liste verilerini Ã§eker:
  - Ä°sim (`a.ext`)
  - Puan/Yorum (`div.rating-container + span`)
  - GÃ¶rÃ¼lme SayÄ±sÄ± (son `td`'nin metni)

#### D. `scrape_detayli_sonuclar(soup)` âœ…
- **div#resultModal** iÃ§indeki `div.results_body` alanÄ±ndan veri Ã§eker:
  - Her `div.bg-light.panel-body` iÃ§in:
    - SÄ±ra (`span.dot`)
    - Ä°sim (`h5`)
    - Puan/Yorum (`div.rating-container + span`)
    - Adres (Yorum sayÄ±sÄ±ndan sonraki `div`)

#### E. `scrape_harita_verileri(soup)` âœ…
- Script etiketlerinden `var pinz = [...]` array'ini bulur
- Regex ile JSON verisini yakalar (`re.search(r'var pinz = (\[.*?\]);', script_text, re.DOTALL)`)
- JSON ayrÄ±ÅŸtÄ±rma ile her pin objesi iÃ§in:
  - `lat`, `lon`, `lable`, `title` bilgilerini Ã§Ä±karÄ±r
  - Temiz bir liste formatÄ±nda dÃ¶ndÃ¼rÃ¼r

### 2. **YardÄ±mcÄ± Fonksiyonlar**

#### A. `get_html_content(url)` âœ…
- URL'den HTML iÃ§eriÄŸini alÄ±r
- User-Agent header'Ä± ile gerÃ§ekÃ§i tarayÄ±cÄ± kimliÄŸi
- 30 saniye timeout
- Hata yÃ¶netimi ile BeautifulSoup objesi dÃ¶ndÃ¼rÃ¼r

#### B. `safe_extract_text(element, default="N/A")` âœ…
- GÃ¼venli metin Ã§Ä±karma
- Element bulunamazsa varsayÄ±lan deÄŸer dÃ¶ndÃ¼rÃ¼r
- Try-except bloklarÄ± ile hata yÃ¶netimi

#### C. `safe_extract_attribute(element, attribute, default="N/A")` âœ…
- GÃ¼venli attribute Ã§Ä±karma
- Element ve attribute varlÄ±ÄŸÄ±nÄ± kontrol eder
- Hata durumunda varsayÄ±lan deÄŸer dÃ¶ndÃ¼rÃ¼r

### 3. **Hata YÃ¶netimi** âœ…
- Her veri Ã§ekme iÅŸlemi iÃ§in try-except bloklarÄ±
- Element bulunamadÄ±ÄŸÄ±nda "N/A" deÄŸeri atanmasÄ±
- HTTP istekleri iÃ§in timeout yÃ¶netimi
- JSON ayrÄ±ÅŸtÄ±rma hatalarÄ± iÃ§in Ã¶zel yakalama
- KapsamlÄ± hata mesajlarÄ±

### 4. **Ana Fonksiyon (`main()`)** âœ…
- TÃ¼m veri Ã§ekme fonksiyonlarÄ±nÄ± sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±r
- SonuÃ§larÄ± JSON dosyasÄ±na kaydeder (`scraped_data.json`)
- Ã–zet istatistikler gÃ¶sterir
- Ä°lerleme durumu bildirimleri

## ğŸ“ Proje DosyalarÄ±

### 1. **web_scraper.py** (16KB, 443 satÄ±r)
- Ana scraping scripti
- TÃ¼m veri Ã§ekme fonksiyonlarÄ±
- Hata yÃ¶netimi ve gÃ¼venlik Ã¶nlemleri
- Type hints ve dokÃ¼mantasyon

### 2. **requirements.txt** (51B, 3 satÄ±r)
- Gerekli Python kÃ¼tÃ¼phaneleri:
  - `requests>=2.31.0`
  - `beautifulsoup4>=4.12.0`
  - `lxml>=4.9.0`

### 3. **README.md** (4.5KB, 196 satÄ±r)
- KapsamlÄ± kullanÄ±m kÄ±lavuzu
- Kurulum talimatlarÄ±
- Ã–rnek kullanÄ±mlar
- Sorun giderme rehberi
- GÃ¼venlik ve etik notlar

### 4. **test_scraper.py** (4.7KB, 159 satÄ±r)
- KÃ¼tÃ¼phane varlÄ±k testleri
- Script import testleri
- HTTP isteÄŸi testleri
- DetaylÄ± test raporlarÄ±

## ğŸš€ KullanÄ±m

### Kurulum
```bash
# Sanal ortam ile
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Sistem paketleri ile (Ubuntu/Debian)
sudo apt install python3-requests python3-bs4 python3-lxml
```

### Ã‡alÄ±ÅŸtÄ±rma
```bash
# Test
python3 test_scraper.py

# Ana script
python3 web_scraper.py
```

### Ã‡Ä±ktÄ±
- `scraped_data.json`: TÃ¼m Ã§ekilen veriler JSON formatÄ±nda
- Konsol Ã§Ä±ktÄ±sÄ±: Ä°lerleme durumu ve Ã¶zet istatistikler

## ğŸ”§ Teknik Ã–zellikler

### Kod Kalitesi
- âœ… Type hints kullanÄ±mÄ±
- âœ… KapsamlÄ± dokÃ¼mantasyon
- âœ… ModÃ¼ler yapÄ±
- âœ… Hata yÃ¶netimi
- âœ… GÃ¼venli veri Ã§Ä±karma

### Performans
- âœ… Timeout yÃ¶netimi
- âœ… Bellek verimli iÅŸlem
- âœ… Optimize edilmiÅŸ selector'lar
- âœ… Batch iÅŸlem desteÄŸi

### GÃ¼venlik
- âœ… User-Agent header'Ä±
- âœ… Input validation
- âœ… Exception handling
- âœ… Safe default values

## ğŸ“Š Veri YapÄ±sÄ±

Script aÅŸaÄŸÄ±daki yapÄ±da veri dÃ¶ndÃ¼rÃ¼r:

```json
{
  "ozet_bilgiler": {
    "isletme_adi": "...",
    "adres": "...",
    "yorum_sayisi": "...",
    "anahtar_kelime_dil": "...",
    "tarih": "...",
    "rank_summary": {...}
  },
  "rakipler": [...],
  "sponsorlu_listeler": [...],
  "detayli_sonuclar": [...],
  "harita_verileri": [...]
}
```

## ğŸ¯ SonuÃ§

Proje tamamen tamamlanmÄ±ÅŸ ve kullanÄ±ma hazÄ±rdÄ±r. TÃ¼m istenen fonksiyonlar implement edilmiÅŸ, hata yÃ¶netimi eklenmiÅŸ ve kapsamlÄ± dokÃ¼mantasyon saÄŸlanmÄ±ÅŸtÄ±r. Script, belirtilen URL'den veri Ã§ekmek iÃ§in gerekli tÃ¼m Ã¶zelliklere sahiptir.